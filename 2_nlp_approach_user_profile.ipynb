{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rec Sys of Answerers for StackOverflow\n",
    "## Version 2.0 - NLP Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_csv(\"dataset/questions_2019.csv\")\n",
    "df_answer = pd.read_csv(\"dataset/answers_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>QuestionOwnerId</th>\n",
       "      <th>QuestionTitle</th>\n",
       "      <th>QuestionTags</th>\n",
       "      <th>QuestionVotes</th>\n",
       "      <th>QuestionCreationDate</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54936100</td>\n",
       "      <td>3419772</td>\n",
       "      <td>R 3.5.2: Error in loading stock data from zoo</td>\n",
       "      <td>['r']</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:00:10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54936106</td>\n",
       "      <td>3997132</td>\n",
       "      <td>Different behaviour of range with lodash/fp</td>\n",
       "      <td>['functional-programming', 'lodash']</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-01 00:01:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54936108</td>\n",
       "      <td>4992551</td>\n",
       "      <td>webPack dev server proxy rewrite URLs in response</td>\n",
       "      <td>['webpack', 'webpack-dev-server']</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-01 00:01:55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54936109</td>\n",
       "      <td>2239552</td>\n",
       "      <td>EF Core 2.0 Global Filter</td>\n",
       "      <td>['c#']</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:02:36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54936112</td>\n",
       "      <td>5505171</td>\n",
       "      <td>Clustered column chart in C# using Chart in Wi...</td>\n",
       "      <td>['c#', 'winforms', 'charts', 'column-chart']</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:02:47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId  QuestionOwnerId  \\\n",
       "0    54936100          3419772   \n",
       "1    54936106          3997132   \n",
       "2    54936108          4992551   \n",
       "3    54936109          2239552   \n",
       "4    54936112          5505171   \n",
       "\n",
       "                                       QuestionTitle  \\\n",
       "0      R 3.5.2: Error in loading stock data from zoo   \n",
       "1        Different behaviour of range with lodash/fp   \n",
       "2  webPack dev server proxy rewrite URLs in response   \n",
       "3                          EF Core 2.0 Global Filter   \n",
       "4  Clustered column chart in C# using Chart in Wi...   \n",
       "\n",
       "                                   QuestionTags  QuestionVotes  \\\n",
       "0                                         ['r']              0   \n",
       "1          ['functional-programming', 'lodash']              1   \n",
       "2             ['webpack', 'webpack-dev-server']              2   \n",
       "3                                        ['c#']              0   \n",
       "4  ['c#', 'winforms', 'charts', 'column-chart']              0   \n",
       "\n",
       "  QuestionCreationDate  AnswerCount  \n",
       "0  2019-03-01 00:00:10            1  \n",
       "1  2019-03-01 00:01:48            1  \n",
       "2  2019-03-01 00:01:55            1  \n",
       "3  2019-03-01 00:02:36            0  \n",
       "4  2019-03-01 00:02:47            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>AnswerOwnerId</th>\n",
       "      <th>AnswerVotes</th>\n",
       "      <th>AnswerCreationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56140111</td>\n",
       "      <td>10245958</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-05-15 00:07:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56140157</td>\n",
       "      <td>1226963</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-15 00:12:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56140125</td>\n",
       "      <td>6841773</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-15 00:12:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56140150</td>\n",
       "      <td>1440565</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-15 00:12:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56140150</td>\n",
       "      <td>11015427</td>\n",
       "      <td>15</td>\n",
       "      <td>2019-05-15 00:16:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId  AnswerOwnerId  AnswerVotes   AnswerCreationDate\n",
       "0    56140111       10245958            3  2019-05-15 00:07:23\n",
       "1    56140157        1226963            0  2019-05-15 00:12:34\n",
       "2    56140125        6841773            0  2019-05-15 00:12:44\n",
       "3    56140150        1440565            5  2019-05-15 00:12:52\n",
       "4    56140150       11015427           15  2019-05-15 00:16:46"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfoming list of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>QuestionOwnerId</th>\n",
       "      <th>QuestionTitle</th>\n",
       "      <th>QuestionTags</th>\n",
       "      <th>QuestionVotes</th>\n",
       "      <th>QuestionCreationDate</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54936100</td>\n",
       "      <td>3419772</td>\n",
       "      <td>R 3.5.2: Error in loading stock data from zoo</td>\n",
       "      <td>[r]</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:00:10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54936106</td>\n",
       "      <td>3997132</td>\n",
       "      <td>Different behaviour of range with lodash/fp</td>\n",
       "      <td>[functional-programming, lodash]</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-01 00:01:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54936108</td>\n",
       "      <td>4992551</td>\n",
       "      <td>webPack dev server proxy rewrite URLs in response</td>\n",
       "      <td>[webpack, webpack-dev-server]</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-01 00:01:55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54936109</td>\n",
       "      <td>2239552</td>\n",
       "      <td>EF Core 2.0 Global Filter</td>\n",
       "      <td>[c#]</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:02:36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54936112</td>\n",
       "      <td>5505171</td>\n",
       "      <td>Clustered column chart in C# using Chart in Wi...</td>\n",
       "      <td>[c#, winforms, charts, column-chart]</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:02:47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878713</th>\n",
       "      <td>54272409</td>\n",
       "      <td>10245420</td>\n",
       "      <td>Selenium iframe Data issue - python</td>\n",
       "      <td>[python, selenium, selenium-webdriver, iframe]</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-19 23:57:14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878714</th>\n",
       "      <td>54272411</td>\n",
       "      <td>8906835</td>\n",
       "      <td>Problem on adding Bootstrap carousel component</td>\n",
       "      <td>[bootstrap-4, bootstrap-carousel]</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-19 23:57:26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878715</th>\n",
       "      <td>54272412</td>\n",
       "      <td>10893334</td>\n",
       "      <td>NativeScript Vue nativescript-sqlite cannot as...</td>\n",
       "      <td>[sqlite, nativescript, nativescript-vue]</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-19 23:57:36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878716</th>\n",
       "      <td>54272414</td>\n",
       "      <td>10564619</td>\n",
       "      <td>How to fix 'TypeError' that comes up for some ...</td>\n",
       "      <td>[python, typeerror]</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-19 23:57:54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878717</th>\n",
       "      <td>54272418</td>\n",
       "      <td>10934024</td>\n",
       "      <td>Getting only a repeating files from directory ...</td>\n",
       "      <td>[powershell, csv, unique, get-childitem]</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-19 23:59:27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>878718 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        QuestionId  QuestionOwnerId  \\\n",
       "0         54936100          3419772   \n",
       "1         54936106          3997132   \n",
       "2         54936108          4992551   \n",
       "3         54936109          2239552   \n",
       "4         54936112          5505171   \n",
       "...            ...              ...   \n",
       "878713    54272409         10245420   \n",
       "878714    54272411          8906835   \n",
       "878715    54272412         10893334   \n",
       "878716    54272414         10564619   \n",
       "878717    54272418         10934024   \n",
       "\n",
       "                                            QuestionTitle  \\\n",
       "0           R 3.5.2: Error in loading stock data from zoo   \n",
       "1             Different behaviour of range with lodash/fp   \n",
       "2       webPack dev server proxy rewrite URLs in response   \n",
       "3                               EF Core 2.0 Global Filter   \n",
       "4       Clustered column chart in C# using Chart in Wi...   \n",
       "...                                                   ...   \n",
       "878713                Selenium iframe Data issue - python   \n",
       "878714     Problem on adding Bootstrap carousel component   \n",
       "878715  NativeScript Vue nativescript-sqlite cannot as...   \n",
       "878716  How to fix 'TypeError' that comes up for some ...   \n",
       "878717  Getting only a repeating files from directory ...   \n",
       "\n",
       "                                          QuestionTags  QuestionVotes  \\\n",
       "0                                                  [r]              0   \n",
       "1                     [functional-programming, lodash]              1   \n",
       "2                        [webpack, webpack-dev-server]              2   \n",
       "3                                                 [c#]              0   \n",
       "4                 [c#, winforms, charts, column-chart]              0   \n",
       "...                                                ...            ...   \n",
       "878713  [python, selenium, selenium-webdriver, iframe]              1   \n",
       "878714               [bootstrap-4, bootstrap-carousel]              0   \n",
       "878715        [sqlite, nativescript, nativescript-vue]              0   \n",
       "878716                             [python, typeerror]              1   \n",
       "878717        [powershell, csv, unique, get-childitem]              1   \n",
       "\n",
       "       QuestionCreationDate  AnswerCount  \n",
       "0       2019-03-01 00:00:10            1  \n",
       "1       2019-03-01 00:01:48            1  \n",
       "2       2019-03-01 00:01:55            1  \n",
       "3       2019-03-01 00:02:36            0  \n",
       "4       2019-03-01 00:02:47            0  \n",
       "...                     ...          ...  \n",
       "878713  2019-01-19 23:57:14            1  \n",
       "878714  2019-01-19 23:57:26            1  \n",
       "878715  2019-01-19 23:57:36            1  \n",
       "878716  2019-01-19 23:57:54            1  \n",
       "878717  2019-01-19 23:59:27            1  \n",
       "\n",
       "[878718 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question['QuestionTags'] = df_question['QuestionTags'].apply(ast.literal_eval)\n",
    "df_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_question['QuestionTags'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Dataset to include only top 5 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags_to_filter = {'java', 'python', 'javascript', 'c#', 'android'}  # Faster lookup structure\n",
    "\n",
    "# # Filter rows where any tag matches one of the target tags\n",
    "# df_question = df_question[df_question['QuestionTags'].apply(lambda tags: any(tag in tags_to_filter for tag in tags))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the question dataset into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordering dataframe before split\n",
    "# Convert 'QuestionCreationDate' to datetime format using .loc\n",
    "df_question.loc[:, 'QuestionCreationDate'] = pd.to_datetime(df_question['QuestionCreationDate'])\n",
    "\n",
    "# Sort the DataFrame by 'QuestionCreationDate' without using inplace\n",
    "df_question = df_question.sort_values(by='QuestionCreationDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the split index\n",
    "split_index = int(len(df_question) * 0.9) #10% for test \n",
    "\n",
    "# Split the DataFrame into training and testing sets\n",
    "train_data = df_question.iloc[:split_index]\n",
    "test_data = df_question.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging QuestionTags to UserAnswerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = train_data[[\"QuestionId\",\"QuestionTitle\",\"QuestionTags\"]].merge(df_answer[[\"QuestionId\", \"AnswerOwnerId\"]], how='inner', on = \"QuestionId\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract list of question of the same user\n",
    "user_question_list = df_merged.groupby(\"AnswerOwnerId\")[\"QuestionTitle\"].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrating User Profile Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf39a2f646104994a91b03d07b6d974a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/15566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load Model\n",
    "# Check device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\").to(device)\n",
    "\n",
    "# Join all question together to speed up embedding process\n",
    "all_questions = []\n",
    "user_question_indices = {}\n",
    "\n",
    "index_counter = 0\n",
    "\n",
    "for user, questions in user_question_list.items():\n",
    "    user_question_indices[user] = (index_counter, index_counter + len(questions)) #Get start and end of user indices\n",
    "    all_questions.extend(questions)\n",
    "    index_counter += len(questions)\n",
    "\n",
    "# Encode all questions in a single batch\n",
    "all_embeddings = model.encode(all_questions, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "# Compute user profile vectors from embeddings\n",
    "user_vectors = {}\n",
    "for user, (start, end) in user_question_indices.items():\n",
    "    user_vectors[user] = np.mean(all_embeddings[start:end], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = list(user_vectors.keys())\n",
    "user_embeddings = np.vstack(list(user_vectors.values()))  # Shape: (num_users, 384)\n",
    "user_embeddings = user_embeddings.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 261369 - Vector size: 384\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of users: {user_embeddings.shape[0]} - Vector size: {user_embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize user embeddings for cosine similarity\n",
    "user_embeddings = user_embeddings / np.linalg.norm(user_embeddings, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of user IDs corresponding to embeddings position\n",
    "user_ids = [i for i in user_vectors.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Unanswered questions embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test = test_data[[\"QuestionId\",\"QuestionTitle\",\"QuestionTags\"]].merge(df_answer[[\"QuestionId\", \"AnswerOwnerId\"]], how='inner', on = \"QuestionId\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unanswered_embedding_index = df_merged_test[\"QuestionId\"].to_list()\n",
    "unanswered_questions = df_merged_test[\"QuestionTitle\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Embedding from Unanswered Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36771a34d149424bbabf7721fee1d932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute embeddings for unanswered questions\n",
    "unanswered_embeddings = model.encode(unanswered_questions, batch_size=64, show_progress_bar=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize unanswered embeddings\n",
    "unanswered_embeddings = unanswered_embeddings / np.linalg.norm(unanswered_embeddings, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unanswered_embeddings = unanswered_embeddings.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providing Recommendation based on Embedding Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity (Matrix multiplication)\n",
    "# Each row is a question and column is a user\n",
    "# similarities = np.dot(unanswered_embeddings, user_embeddings.T)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative method to avoid memory overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 110/110 [39:21<00:00, 21.47s/it]\n"
     ]
    }
   ],
   "source": [
    "import gc  # Garbage collector\n",
    "\n",
    "def get_recommendation_top_batched(top_n, batch_size=1000):\n",
    "    num_test = unanswered_embeddings.shape[0]\n",
    "\n",
    "    for start in tqdm(range(0, num_test, batch_size), desc=\"Processing Batches\"):\n",
    "        end = min(start + batch_size, num_test)\n",
    "        batch = unanswered_embeddings[start:end]\n",
    "\n",
    "        # Compute similarities (rows = questions, columns = users)\n",
    "        batch_similarities = np.dot(batch, user_embeddings.T) \n",
    "\n",
    "        # Get top-N indices \n",
    "        top_indices = np.argsort(-batch_similarities, axis=1)[:, :top_n] \n",
    "        \n",
    "        del batch_similarities  \n",
    "        gc.collect()  # Force Python to release memory\n",
    "\n",
    "        # Yield results one batch at a time\n",
    "        for i, question_id in enumerate(unanswered_embedding_index[start:end]):\n",
    "            yield question_id, [user_ids[j] for j in top_indices[i]]\n",
    "\n",
    "# Use the generator directly instead of storing everything\n",
    "dic_recommendation = {qid: recommendations for qid, recommendations in get_recommendation_top_batched(top_n=100)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping our **ground truth** that is the users that answered the question in real life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert QuestionTags from lists to tuples\n",
    "df_merged_test[\"QuestionTags\"] = df_merged_test[\"QuestionTags\"].apply(tuple)\n",
    "\n",
    "# Group AnswerOwnerId by QuestionId and QuestionTags\n",
    "grouped_df = (\n",
    "    df_merged_test.groupby([\"QuestionId\", \"QuestionTags\", \"QuestionTitle\"])[\"AnswerOwnerId\"]\n",
    "    .apply(list)  # Combine AnswerOwnerId values into a list\n",
    "    .reset_index()\n",
    "    .rename(columns={\"AnswerOwnerId\": \"GroundTruth\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_dic = grouped_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Ground Truth with Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_accuracy(ground_truth_dic, top_users_list, top_n):\n",
    "    tp = 0\n",
    "    \n",
    "    for question in ground_truth_dic:    \n",
    "        # Checking if it is in the answer\n",
    "        users_recommendation = top_users_list[question[\"QuestionId\"]][:top_n]\n",
    "        users_ground_truth = question[\"GroundTruth\"]\n",
    "        if set(users_recommendation) & set(users_ground_truth):\n",
    "            tp += 1\n",
    "            \n",
    "    print(tp)\n",
    "    return tp/len(ground_truth_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(users_ground_truth_list, users_recommendation_list, top_n):\n",
    "\n",
    "    total_recall = 0\n",
    "    successful_recommendations = 0\n",
    "    num_questions = len(users_ground_truth_list)\n",
    "\n",
    "    for users_ground_truth, users_rec in zip(users_ground_truth_list, users_recommendation_list):\n",
    "        # Get the top-N recommended users\n",
    "        users_recommendation = users_rec[:top_n]\n",
    "        # Convert to sets for intersection\n",
    "        recommended_set = set(users_recommendation)\n",
    "        ground_truth_set = set(users_ground_truth)\n",
    "        # Calculate the number of relevant users in the top-N recommendations\n",
    "        true_positives = len(recommended_set & ground_truth_set)\n",
    "        # Recall@N: Proportion of relevant users that are recommended in top-N\n",
    "        recall = true_positives / len(ground_truth_set) if ground_truth_set else 0\n",
    "        # Accumulate recall\n",
    "        total_recall += recall\n",
    "        # Accuracy@N: Check if there's at least one relevant user in the top-N recommendations\n",
    "        if true_positives > 0:\n",
    "            successful_recommendations += 1\n",
    "\n",
    "    # Calculate average recall over all questions\n",
    "    avg_recall = total_recall / num_questions if num_questions > 0 else 0\n",
    "    # Calculate accuracy over all questions\n",
    "    accuracy = successful_recommendations / num_questions if num_questions > 0 else 0\n",
    "\n",
    "    return avg_recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ground_truth = [ground_truth_item[\"GroundTruth\"] for ground_truth_item in ground_truth_dic]\n",
    "users_recommendation_list = [dic_recommendation[item[\"QuestionId\"]] for item in ground_truth_dic]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.0528874873233958, 'recall': 0.043657847593740716, 'top': 5, 'type': 'nlp_sentence_transformer_user_profile'}\n",
      "{'acc': 0.07728213605990303, 'recall': 0.06353413723807252, 'top': 10, 'type': 'nlp_sentence_transformer_user_profile'}\n",
      "{'acc': 0.10903963435811233, 'recall': 0.08873387465402718, 'top': 20, 'type': 'nlp_sentence_transformer_user_profile'}\n",
      "{'acc': 0.16245502410291318, 'recall': 0.13149090241888634, 'top': 50, 'type': 'nlp_sentence_transformer_user_profile'}\n",
      "{'acc': 0.20903546670741702, 'recall': 0.16957004716970364, 'top': 100, 'type': 'nlp_sentence_transformer_user_profile'}\n"
     ]
    }
   ],
   "source": [
    "top_users = [5, 10, 20, 50, 100]\n",
    "results = []\n",
    "\n",
    "for top in top_users:\n",
    "    recall, acc = evaluate_recommendations(users_ground_truth, users_recommendation_list, top)\n",
    "    result = {\n",
    "        \"acc\": acc,\n",
    "        \"recall\": recall,\n",
    "        \"top\": top,\n",
    "        \"type\": \"nlp_sentence_transformer_user_profile\"\n",
    "    }\n",
    "    \n",
    "    print(result)\n",
    "    results.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'acc': 0.0528874873233958,\n",
       "  'recall': 0.043657847593740716,\n",
       "  'top': 5,\n",
       "  'type': 'nlp_sentence_transformer_user_profile'},\n",
       " {'acc': 0.07728213605990303,\n",
       "  'recall': 0.06353413723807252,\n",
       "  'top': 10,\n",
       "  'type': 'nlp_sentence_transformer_user_profile'},\n",
       " {'acc': 0.10903963435811233,\n",
       "  'recall': 0.08873387465402718,\n",
       "  'top': 20,\n",
       "  'type': 'nlp_sentence_transformer_user_profile'},\n",
       " {'acc': 0.16245502410291318,\n",
       "  'recall': 0.13149090241888634,\n",
       "  'top': 50,\n",
       "  'type': 'nlp_sentence_transformer_user_profile'},\n",
       " {'acc': 0.20903546670741702,\n",
       "  'recall': 0.16957004716970364,\n",
       "  'top': 100,\n",
       "  'type': 'nlp_sentence_transformer_user_profile'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"setup2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
