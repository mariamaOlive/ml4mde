{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rec Sys of Answerers for StackOverflow\n",
    "## Version 2.2 - NLP Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_csv(\"dataset/questions_2019.csv\")\n",
    "df_answer = pd.read_csv(\"dataset/answers_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>QuestionOwnerId</th>\n",
       "      <th>QuestionTitle</th>\n",
       "      <th>QuestionTags</th>\n",
       "      <th>QuestionVotes</th>\n",
       "      <th>QuestionCreationDate</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54936100</td>\n",
       "      <td>3419772</td>\n",
       "      <td>R 3.5.2: Error in loading stock data from zoo</td>\n",
       "      <td>['r']</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:00:10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54936106</td>\n",
       "      <td>3997132</td>\n",
       "      <td>Different behaviour of range with lodash/fp</td>\n",
       "      <td>['functional-programming', 'lodash']</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-01 00:01:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54936108</td>\n",
       "      <td>4992551</td>\n",
       "      <td>webPack dev server proxy rewrite URLs in response</td>\n",
       "      <td>['webpack', 'webpack-dev-server']</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-01 00:01:55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54936109</td>\n",
       "      <td>2239552</td>\n",
       "      <td>EF Core 2.0 Global Filter</td>\n",
       "      <td>['c#']</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:02:36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54936112</td>\n",
       "      <td>5505171</td>\n",
       "      <td>Clustered column chart in C# using Chart in Wi...</td>\n",
       "      <td>['c#', 'winforms', 'charts', 'column-chart']</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:02:47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId  QuestionOwnerId  \\\n",
       "0    54936100          3419772   \n",
       "1    54936106          3997132   \n",
       "2    54936108          4992551   \n",
       "3    54936109          2239552   \n",
       "4    54936112          5505171   \n",
       "\n",
       "                                       QuestionTitle  \\\n",
       "0      R 3.5.2: Error in loading stock data from zoo   \n",
       "1        Different behaviour of range with lodash/fp   \n",
       "2  webPack dev server proxy rewrite URLs in response   \n",
       "3                          EF Core 2.0 Global Filter   \n",
       "4  Clustered column chart in C# using Chart in Wi...   \n",
       "\n",
       "                                   QuestionTags  QuestionVotes  \\\n",
       "0                                         ['r']              0   \n",
       "1          ['functional-programming', 'lodash']              1   \n",
       "2             ['webpack', 'webpack-dev-server']              2   \n",
       "3                                        ['c#']              0   \n",
       "4  ['c#', 'winforms', 'charts', 'column-chart']              0   \n",
       "\n",
       "  QuestionCreationDate  AnswerCount  \n",
       "0  2019-03-01 00:00:10            1  \n",
       "1  2019-03-01 00:01:48            1  \n",
       "2  2019-03-01 00:01:55            1  \n",
       "3  2019-03-01 00:02:36            0  \n",
       "4  2019-03-01 00:02:47            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>AnswerOwnerId</th>\n",
       "      <th>AnswerVotes</th>\n",
       "      <th>AnswerCreationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56140111</td>\n",
       "      <td>10245958</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-05-15 00:07:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56140157</td>\n",
       "      <td>1226963</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-15 00:12:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56140125</td>\n",
       "      <td>6841773</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-15 00:12:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56140150</td>\n",
       "      <td>1440565</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-15 00:12:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56140150</td>\n",
       "      <td>11015427</td>\n",
       "      <td>15</td>\n",
       "      <td>2019-05-15 00:16:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId  AnswerOwnerId  AnswerVotes   AnswerCreationDate\n",
       "0    56140111       10245958            3  2019-05-15 00:07:23\n",
       "1    56140157        1226963            0  2019-05-15 00:12:34\n",
       "2    56140125        6841773            0  2019-05-15 00:12:44\n",
       "3    56140150        1440565            5  2019-05-15 00:12:52\n",
       "4    56140150       11015427           15  2019-05-15 00:16:46"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfoming list of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question['QuestionTags'] = df_question['QuestionTags'].apply(ast.literal_eval)\n",
    "# df_question = df_question.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_question['QuestionTags'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Dataset to include only top 5 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags_to_filter = {'java', 'python', 'javascript', 'c#', 'android'}  # Faster lookup structure\n",
    "\n",
    "# # Filter rows where any tag matches one of the target tags\n",
    "# df_question = df_question[df_question['QuestionTags'].apply(lambda tags: any(tag in tags_to_filter for tag in tags))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the question dataset into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordering dataframe before split\n",
    "# Convert 'QuestionCreationDate' to datetime format using .loc\n",
    "df_question.loc[:, 'QuestionCreationDate'] = pd.to_datetime(df_question['QuestionCreationDate'])\n",
    "\n",
    "# Sort the DataFrame by 'QuestionCreationDate' without using inplace\n",
    "df_question = df_question.sort_values(by='QuestionCreationDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the split index\n",
    "split_index = int(len(df_question) * 0.9) #20% for test \n",
    "\n",
    "# Split the DataFrame into training and testing sets\n",
    "train_data = df_question.iloc[:split_index]\n",
    "test_data = df_question.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging QuestionTags to UserAnswerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = train_data[[\"QuestionId\",\"QuestionTitle\",\"QuestionTags\"]].merge(df_answer[[\"QuestionId\", \"AnswerOwnerId\"]], how='inner', on = \"QuestionId\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"QuestionTags\"]=df_merged[\"QuestionTags\"].apply(sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting values to be embedded and list of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_questions = df_merged[\"QuestionTitle\"].tolist()\n",
    "list_tags =  [' '.join(tags) for tags in df_merged[\"QuestionTags\"].tolist()]\n",
    "list_users = df_merged[\"AnswerOwnerId\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrating Question Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f121bb0871274c11a505c9db941d2dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/15566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\").to(device)\n",
    "\n",
    "# Encode all questions in a single batch\n",
    "all_embeddings = model.encode(list_questions, batch_size=64, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2f5babb784460b9662df50e63dc968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/15566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_embeddings_tags = model.encode(list_tags, batch_size=64, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_embedding = np.concatenate((all_embeddings, all_embeddings_tags), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize user embeddings for cosine similarity\n",
    "concat_embedding = concat_embedding / np.linalg.norm(concat_embedding, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Unanswered questions embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test = test_data[[\"QuestionId\",\"QuestionTitle\",\"QuestionTags\"]].merge(df_answer[[\"QuestionId\", \"AnswerOwnerId\"]], how='inner', on = \"QuestionId\", )\n",
    "# df_merged_test = df_merged_test.iloc[:1000] #REMOVE: Here for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test[\"QuestionTags\"]=df_merged_test[\"QuestionTags\"].apply(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unanswered_embedding_index = df_merged_test[\"QuestionId\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unanswered_questions = df_merged_test[\"QuestionTitle\"].to_list()\n",
    "unanswered_questions_tags =  [' '.join(tags) for tags in df_merged_test[\"QuestionTags\"].tolist()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Embedding from Unanswered Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f843f06cb9c948cab72512f23b1e9125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute embeddings for unanswered questions\n",
    "unanswered_embeddings = model.encode(unanswered_questions, batch_size=64, show_progress_bar=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425c6dd0b0434be9bcdacbd3a804867f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unanswered_tags_embeddings = model.encode(unanswered_questions_tags, batch_size=64, show_progress_bar=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_unanswered_embedding = np.concatenate((unanswered_embeddings, unanswered_tags_embeddings), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize unanswered embeddings\n",
    "concat_unanswered_embedding = concat_unanswered_embedding / np.linalg.norm(concat_unanswered_embedding, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_unanswered_embedding = concat_unanswered_embedding.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providing Recommendation based on Embedding Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity (Matrix multiplication)\n",
    "# Each row is a question and column is a user\n",
    "# similarities = np.dot(unanswered_embeddings, user_embeddings.T)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative method to avoid memory overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  73%|███████▎  | 115/157 [2:08:27<49:42, 71.01s/it]  "
     ]
    }
   ],
   "source": [
    "import gc  # Garbage collector\n",
    "\n",
    "def get_recommendation_top_batched(top_n, batch_size=700):\n",
    "    num_test = concat_unanswered_embedding.shape[0]\n",
    "\n",
    "    for start in tqdm(range(0, num_test, batch_size), desc=\"Processing Batches\"):\n",
    "        end = min(start + batch_size, num_test)\n",
    "        batch = concat_unanswered_embedding[start:end]\n",
    "\n",
    "        # Compute similarities (rows = questions, columns = question of a user)\n",
    "        batch_similarities = np.dot(batch, concat_embedding.T) \n",
    "\n",
    "        # Get top-N indices \n",
    "        top_indices = np.argsort(-batch_similarities, axis=1)[:, :top_n] \n",
    "        \n",
    "        del batch_similarities  \n",
    "        gc.collect()  # Force Python to release memory\n",
    "        # print(top_indices)\n",
    "        # Yield results one batch at a time\n",
    "        for i, question_id in enumerate(unanswered_embedding_index[start:end]):\n",
    "            yield question_id, [list_users[j] for j in top_indices[i]]\n",
    "\n",
    "# Use the generator directly instead of storing everything\n",
    "dic_recommendation = {qid: recommendations for qid, recommendations in get_recommendation_top_batched(top_n=1000)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeats_numpy(arr):\n",
    "    row, idx = np.unique(arr, return_index=True)  # Get unique values and first occurrence index\n",
    "    sorted_row = row[idx.argsort()] # Sort by the original order\n",
    "    return np.array(sorted_row, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_recommendation =  {qid: remove_repeats_numpy(recommendations) for qid, recommendations in dic_recommendation.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping our **ground truth** that is the users that answered the question in real life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert QuestionTags from lists to tuples\n",
    "df_merged_test[\"QuestionTags\"] = df_merged_test[\"QuestionTags\"].apply(tuple)\n",
    "\n",
    "# Group AnswerOwnerId by QuestionId and QuestionTags\n",
    "grouped_df = (\n",
    "    df_merged_test.groupby([\"QuestionId\", \"QuestionTags\", \"QuestionTitle\"])[\"AnswerOwnerId\"]\n",
    "    .apply(list)  # Combine AnswerOwnerId values into a list\n",
    "    .reset_index()\n",
    "    .rename(columns={\"AnswerOwnerId\": \"GroundTruth\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_dic = grouped_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Ground Truth with Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_accuracy(ground_truth_dic, top_users_list, top_n):\n",
    "    tp = 0\n",
    "    \n",
    "    for question in ground_truth_dic:    \n",
    "        # Checking if it is in the answer\n",
    "        users_recommendation = top_users_list[question[\"QuestionId\"]][:top_n]\n",
    "        users_ground_truth = question[\"GroundTruth\"]\n",
    "        if set(users_recommendation) & set(users_ground_truth):\n",
    "            tp += 1\n",
    "            \n",
    "    print(tp)\n",
    "    return tp/len(ground_truth_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(users_ground_truth_list, users_recommendation_list, top_n):\n",
    "\n",
    "    total_recall = 0\n",
    "    successful_recommendations = 0\n",
    "    num_questions = len(users_ground_truth_list)\n",
    "\n",
    "    for users_ground_truth, users_rec in zip(users_ground_truth_list, users_recommendation_list):\n",
    "        # Get the top-N recommended users\n",
    "        users_recommendation = users_rec[:top_n]\n",
    "        # Convert to sets for intersection\n",
    "        recommended_set = set(users_recommendation)\n",
    "        ground_truth_set = set(users_ground_truth)\n",
    "        # Calculate the number of relevant users in the top-N recommendations\n",
    "        true_positives = len(recommended_set & ground_truth_set)\n",
    "        # Recall@N: Proportion of relevant users that are recommended in top-N\n",
    "        recall = true_positives / len(ground_truth_set) if ground_truth_set else 0\n",
    "        # Accumulate recall\n",
    "        total_recall += recall\n",
    "        # Accuracy@N: Check if there's at least one relevant user in the top-N recommendations\n",
    "        if true_positives > 0:\n",
    "            successful_recommendations += 1\n",
    "\n",
    "    # Calculate average recall over all questions\n",
    "    avg_recall = total_recall / num_questions if num_questions > 0 else 0\n",
    "    # Calculate accuracy over all questions\n",
    "    accuracy = successful_recommendations / num_questions if num_questions > 0 else 0\n",
    "\n",
    "    return avg_recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ground_truth = [ground_truth_item[\"GroundTruth\"] for ground_truth_item in ground_truth_dic]\n",
    "users_recommendation_list = [dic_recommendation[item[\"QuestionId\"]] for item in ground_truth_dic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.12944723059611296, 'recall': 0.10402387764278356, 'top': 5, 'type': 'nlp_sentence_transformer_question_tags'}\n",
      "{'acc': 0.18112609921787087, 'recall': 0.14580530821288817, 'top': 10, 'type': 'nlp_sentence_transformer_question_tags'}\n",
      "{'acc': 0.23647250045149548, 'recall': 0.19155167981597393, 'top': 20, 'type': 'nlp_sentence_transformer_question_tags'}\n",
      "{'acc': 0.31792228720670157, 'recall': 0.25977171435388696, 'top': 50, 'type': 'nlp_sentence_transformer_question_tags'}\n",
      "{'acc': 0.3789922620618757, 'recall': 0.31233413399790727, 'top': 100, 'type': 'nlp_sentence_transformer_question_tags'}\n"
     ]
    }
   ],
   "source": [
    "top_users = [5, 10, 20, 50, 100]\n",
    "results = []\n",
    "\n",
    "for top in top_users:\n",
    "    recall, acc = evaluate_recommendations(users_ground_truth, users_recommendation_list, top)\n",
    "    result = {\n",
    "        \"acc\": acc,\n",
    "        \"recall\": recall,\n",
    "        \"top\": top,\n",
    "        \"type\": \"nlp_sentence_transformer_question_tags\"\n",
    "    }\n",
    "    \n",
    "    print(result)\n",
    "    results.append(result)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"setup4_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
