{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rec Sys of Answerers for StackOverflow\n",
    "## Version 1.0 - NLP Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_csv(\"dataset/questions_2019.csv\")\n",
    "df_answer = pd.read_csv(\"dataset/answers_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>QuestionOwnerId</th>\n",
       "      <th>QuestionTitle</th>\n",
       "      <th>QuestionTags</th>\n",
       "      <th>QuestionVotes</th>\n",
       "      <th>QuestionCreationDate</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54936100</td>\n",
       "      <td>3419772</td>\n",
       "      <td>R 3.5.2: Error in loading stock data from zoo</td>\n",
       "      <td>['r']</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:00:10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54936106</td>\n",
       "      <td>3997132</td>\n",
       "      <td>Different behaviour of range with lodash/fp</td>\n",
       "      <td>['functional-programming', 'lodash']</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-01 00:01:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54936108</td>\n",
       "      <td>4992551</td>\n",
       "      <td>webPack dev server proxy rewrite URLs in response</td>\n",
       "      <td>['webpack', 'webpack-dev-server']</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-01 00:01:55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54936109</td>\n",
       "      <td>2239552</td>\n",
       "      <td>EF Core 2.0 Global Filter</td>\n",
       "      <td>['c#']</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:02:36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54936112</td>\n",
       "      <td>5505171</td>\n",
       "      <td>Clustered column chart in C# using Chart in Wi...</td>\n",
       "      <td>['c#', 'winforms', 'charts', 'column-chart']</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:02:47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId  QuestionOwnerId  \\\n",
       "0    54936100          3419772   \n",
       "1    54936106          3997132   \n",
       "2    54936108          4992551   \n",
       "3    54936109          2239552   \n",
       "4    54936112          5505171   \n",
       "\n",
       "                                       QuestionTitle  \\\n",
       "0      R 3.5.2: Error in loading stock data from zoo   \n",
       "1        Different behaviour of range with lodash/fp   \n",
       "2  webPack dev server proxy rewrite URLs in response   \n",
       "3                          EF Core 2.0 Global Filter   \n",
       "4  Clustered column chart in C# using Chart in Wi...   \n",
       "\n",
       "                                   QuestionTags  QuestionVotes  \\\n",
       "0                                         ['r']              0   \n",
       "1          ['functional-programming', 'lodash']              1   \n",
       "2             ['webpack', 'webpack-dev-server']              2   \n",
       "3                                        ['c#']              0   \n",
       "4  ['c#', 'winforms', 'charts', 'column-chart']              0   \n",
       "\n",
       "  QuestionCreationDate  AnswerCount  \n",
       "0  2019-03-01 00:00:10            1  \n",
       "1  2019-03-01 00:01:48            1  \n",
       "2  2019-03-01 00:01:55            1  \n",
       "3  2019-03-01 00:02:36            0  \n",
       "4  2019-03-01 00:02:47            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>AnswerOwnerId</th>\n",
       "      <th>AnswerVotes</th>\n",
       "      <th>AnswerCreationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56140111</td>\n",
       "      <td>10245958</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-05-15 00:07:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56140157</td>\n",
       "      <td>1226963</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-15 00:12:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56140125</td>\n",
       "      <td>6841773</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-15 00:12:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56140150</td>\n",
       "      <td>1440565</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-15 00:12:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56140150</td>\n",
       "      <td>11015427</td>\n",
       "      <td>15</td>\n",
       "      <td>2019-05-15 00:16:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId  AnswerOwnerId  AnswerVotes   AnswerCreationDate\n",
       "0    56140111       10245958            3  2019-05-15 00:07:23\n",
       "1    56140157        1226963            0  2019-05-15 00:12:34\n",
       "2    56140125        6841773            0  2019-05-15 00:12:44\n",
       "3    56140150        1440565            5  2019-05-15 00:12:52\n",
       "4    56140150       11015427           15  2019-05-15 00:16:46"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfoming list of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>QuestionOwnerId</th>\n",
       "      <th>QuestionTitle</th>\n",
       "      <th>QuestionTags</th>\n",
       "      <th>QuestionVotes</th>\n",
       "      <th>QuestionCreationDate</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54936100</td>\n",
       "      <td>3419772</td>\n",
       "      <td>R 3.5.2: Error in loading stock data from zoo</td>\n",
       "      <td>[r]</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:00:10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54936106</td>\n",
       "      <td>3997132</td>\n",
       "      <td>Different behaviour of range with lodash/fp</td>\n",
       "      <td>[functional-programming, lodash]</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-01 00:01:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54936108</td>\n",
       "      <td>4992551</td>\n",
       "      <td>webPack dev server proxy rewrite URLs in response</td>\n",
       "      <td>[webpack, webpack-dev-server]</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-01 00:01:55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54936109</td>\n",
       "      <td>2239552</td>\n",
       "      <td>EF Core 2.0 Global Filter</td>\n",
       "      <td>[c#]</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:02:36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54936112</td>\n",
       "      <td>5505171</td>\n",
       "      <td>Clustered column chart in C# using Chart in Wi...</td>\n",
       "      <td>[c#, winforms, charts, column-chart]</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:02:47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878713</th>\n",
       "      <td>54272409</td>\n",
       "      <td>10245420</td>\n",
       "      <td>Selenium iframe Data issue - python</td>\n",
       "      <td>[python, selenium, selenium-webdriver, iframe]</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-19 23:57:14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878714</th>\n",
       "      <td>54272411</td>\n",
       "      <td>8906835</td>\n",
       "      <td>Problem on adding Bootstrap carousel component</td>\n",
       "      <td>[bootstrap-4, bootstrap-carousel]</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-19 23:57:26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878715</th>\n",
       "      <td>54272412</td>\n",
       "      <td>10893334</td>\n",
       "      <td>NativeScript Vue nativescript-sqlite cannot as...</td>\n",
       "      <td>[sqlite, nativescript, nativescript-vue]</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-19 23:57:36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878716</th>\n",
       "      <td>54272414</td>\n",
       "      <td>10564619</td>\n",
       "      <td>How to fix 'TypeError' that comes up for some ...</td>\n",
       "      <td>[python, typeerror]</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-19 23:57:54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878717</th>\n",
       "      <td>54272418</td>\n",
       "      <td>10934024</td>\n",
       "      <td>Getting only a repeating files from directory ...</td>\n",
       "      <td>[powershell, csv, unique, get-childitem]</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-19 23:59:27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>878718 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        QuestionId  QuestionOwnerId  \\\n",
       "0         54936100          3419772   \n",
       "1         54936106          3997132   \n",
       "2         54936108          4992551   \n",
       "3         54936109          2239552   \n",
       "4         54936112          5505171   \n",
       "...            ...              ...   \n",
       "878713    54272409         10245420   \n",
       "878714    54272411          8906835   \n",
       "878715    54272412         10893334   \n",
       "878716    54272414         10564619   \n",
       "878717    54272418         10934024   \n",
       "\n",
       "                                            QuestionTitle  \\\n",
       "0           R 3.5.2: Error in loading stock data from zoo   \n",
       "1             Different behaviour of range with lodash/fp   \n",
       "2       webPack dev server proxy rewrite URLs in response   \n",
       "3                               EF Core 2.0 Global Filter   \n",
       "4       Clustered column chart in C# using Chart in Wi...   \n",
       "...                                                   ...   \n",
       "878713                Selenium iframe Data issue - python   \n",
       "878714     Problem on adding Bootstrap carousel component   \n",
       "878715  NativeScript Vue nativescript-sqlite cannot as...   \n",
       "878716  How to fix 'TypeError' that comes up for some ...   \n",
       "878717  Getting only a repeating files from directory ...   \n",
       "\n",
       "                                          QuestionTags  QuestionVotes  \\\n",
       "0                                                  [r]              0   \n",
       "1                     [functional-programming, lodash]              1   \n",
       "2                        [webpack, webpack-dev-server]              2   \n",
       "3                                                 [c#]              0   \n",
       "4                 [c#, winforms, charts, column-chart]              0   \n",
       "...                                                ...            ...   \n",
       "878713  [python, selenium, selenium-webdriver, iframe]              1   \n",
       "878714               [bootstrap-4, bootstrap-carousel]              0   \n",
       "878715        [sqlite, nativescript, nativescript-vue]              0   \n",
       "878716                             [python, typeerror]              1   \n",
       "878717        [powershell, csv, unique, get-childitem]              1   \n",
       "\n",
       "       QuestionCreationDate  AnswerCount  \n",
       "0       2019-03-01 00:00:10            1  \n",
       "1       2019-03-01 00:01:48            1  \n",
       "2       2019-03-01 00:01:55            1  \n",
       "3       2019-03-01 00:02:36            0  \n",
       "4       2019-03-01 00:02:47            0  \n",
       "...                     ...          ...  \n",
       "878713  2019-01-19 23:57:14            1  \n",
       "878714  2019-01-19 23:57:26            1  \n",
       "878715  2019-01-19 23:57:36            1  \n",
       "878716  2019-01-19 23:57:54            1  \n",
       "878717  2019-01-19 23:59:27            1  \n",
       "\n",
       "[878718 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question['QuestionTags'] = df_question['QuestionTags'].apply(ast.literal_eval)\n",
    "df_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_question['QuestionTags'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Dataset to include only top 5 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_to_filter = {'java', 'python', 'javascript', 'c#', 'android'}  # Faster lookup structure\n",
    "\n",
    "# Filter rows where any tag matches one of the target tags\n",
    "filtered_df = df_question[df_question['QuestionTags'].apply(lambda tags: any(tag in tags_to_filter for tag in tags))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the question dataset into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(filtered_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging QuestionTags to UserAnswerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = train_data[[\"QuestionId\",\"QuestionTitle\",\"QuestionTags\"]].merge(df_answer[[\"QuestionId\", \"AnswerOwnerId\"]], how='inner', on = \"QuestionId\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_user_questions = df_merged.groupby(\"AnswerOwnerId\").apply(lambda x: x[['QuestionTitle', 'QuestionTags']].to_dict(orient='records')).to_dict()\n",
    "\n",
    "# Extract list of question of the same user\n",
    "# user_question_list = df_merged.groupby(\"AnswerOwnerId\")[\"QuestionTitle\", \"QuestionTags\"].apply(list).to_dict()\n",
    "# user_question_list = df_merged.iloc[:1000].groupby(\"AnswerOwnerId\")[\"QuestionTitle\"].apply(list).to_dict() #REMOVE: here for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrating User Profile Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load transformer model \n",
    "\n",
    "# # Check if GPU is available\n",
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "# print(f\"Using device: {device}\")\n",
    "# model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\").to(device)\n",
    "\n",
    "# # Computing user vector \n",
    "# user_vectors = {}\n",
    "# for user, questions in tqdm(user_question_list.items(), desc=\"Computing user profile vector\"):\n",
    "#     question_embeddings = model.encode(questions)  # Process in batch the questions of the same user\n",
    "#     user_profile_vector = np.mean(question_embeddings, axis=0)  \n",
    "#     user_vectors[user] = user_profile_vector \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1dcfa24e6ac4f20be71d79304932c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract unique tags\n",
    "unique_tags = {tag for sublist in df_merged['QuestionTags'] for tag in sublist}\n",
    "\n",
    "# Convert the set to a list (optional)\n",
    "unique_tags = list(unique_tags)\n",
    "\n",
    "# Get Embedding for all tags\n",
    "tags_embedding =  model.encode(unique_tags, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "dic_tags_embedding = {tag: embedding for tag, embedding in zip(unique_tags, tags_embedding)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all question together to speed up embedding process\n",
    "all_questions = []\n",
    "user_question_indices = {}\n",
    "\n",
    "index_counter = 0\n",
    "\n",
    "for user, questions in dic_user_questions.items():\n",
    "    user_question_indices[user] = (index_counter, index_counter + len(questions)) #Get start and end of user indices\n",
    "    for question in questions:\n",
    "        all_questions.append(question[\"QuestionTitle\"])\n",
    "    index_counter += len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e537bb52dc84f1b97aca2e54f3d41b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode all questions in a single batch\n",
    "all_embeddings = model.encode(all_questions, batch_size=64, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409027, 384)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127581"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_vectors.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate title and tag embedding \n",
    "user_tag_embedding = {}\n",
    "for user, questions in dic_user_questions.items():\n",
    "    user_vectors_tags = []\n",
    "    for question in questions:\n",
    "        user_vectors_tags.extend(question[\"QuestionTags\"])\n",
    "    unique_embedding_user = set(user_vectors_tags)\n",
    "    \n",
    "    tag_embeddings = [dic_tags_embedding[tag_emb] for tag_emb in unique_embedding_user]\n",
    "    user_tag_embedding[user]= np.mean(tag_embeddings, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute user profile vectors from embeddings\n",
    "user_vectors = {}\n",
    "for user, (start, end) in user_question_indices.items():\n",
    "    titles_embedding = np.mean(all_embeddings[start:end], axis=0)\n",
    "    user_vectors[user] = np.concatenate((titles_embedding, user_tag_embedding[user]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = list(user_vectors.keys()) # used later to when getting user for recommendation\n",
    "user_embeddings = np.vstack(list(user_vectors.values()))  # Shape: (num_users, 384)\n",
    "user_embeddings = user_embeddings.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 127581 - Vector size: 768\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of users: {user_embeddings.shape[0]} - Vector size: {user_embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize user embeddings for cosine similarity\n",
    "user_embeddings = user_embeddings / np.linalg.norm(user_embeddings, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Unanswered questions embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test = test_data[[\"QuestionId\",\"QuestionTitle\",\"QuestionTags\"]].merge(df_answer[[\"QuestionId\", \"AnswerOwnerId\"]], how='inner', on = \"QuestionId\", )\n",
    "# df_merged_test = df_merged_test.iloc[:1000] #REMOVE: Here for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unanswered_embedding_index = df_merged_test[\"QuestionId\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unanswered_questions = df_merged_test[\"QuestionTitle\"].to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Embedding from Unanswered Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb051ba07ce4543832764caa486b0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute embeddings for unanswered questions\n",
    "unanswered_embeddings = model.encode(unanswered_questions, batch_size=64, show_progress_bar=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Tag Embedding from Unanswered Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d50014bffb4d879cec6ad94f07d922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract unique tags\n",
    "unique_tags_test = {tag for sublist in df_merged_test['QuestionTags'] for tag in sublist}\n",
    "\n",
    "# Convert the set to a list (optional)\n",
    "unique_tags_test = list(unique_tags_test)\n",
    "\n",
    "# Get Embedding for all tags\n",
    "tags_embedding_test =  model.encode(unique_tags_test, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "dic_tags_embedding_test = {tag: embedding for tag, embedding in zip(unique_tags_test, tags_embedding_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tags_new_questions = df_merged_test['QuestionTags'].to_list()\n",
    "new_question_tag_embedding = []\n",
    "for tags in list_tags_new_questions:\n",
    "    tag_embeddings = [dic_tags_embedding_test[tag] for tag in tags]\n",
    "    new_question_tag_embedding.append(np.mean(tag_embeddings, axis=0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45645, 384)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unanswered_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "unanswered_embeddings_concat = np.concatenate((unanswered_embeddings, new_question_tag_embedding), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45645, 768)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unanswered_embeddings_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize unanswered embeddings\n",
    "unanswered_embeddings = unanswered_embeddings_concat / np.linalg.norm(unanswered_embeddings_concat, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "unanswered_embeddings = unanswered_embeddings.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providing Recommendation based on Embedding Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity (Matrix multiplication)\n",
    "# Each row is a question and column is a user\n",
    "# similarities = np.dot(unanswered_embeddings, user_embeddings.T)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dictionary QuestionId and Top Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_recommendation_top(top_n):\n",
    "#     top_indices = np.argsort(-similarities, axis=1)[:, :top_n]  # Negative for descending sort\n",
    "#     # top_scores = np.sort(-similarities, axis=1)[:, :top_n]\n",
    "#     # top_scores = - top_scores\n",
    "    \n",
    "#     # Map indices to the ones in the dataset\n",
    "#     top_system_id = []\n",
    "#     for indices_list in top_indices: \n",
    "#         mapping = []\n",
    "#         for i in indices_list:\n",
    "#             mapping.append(user_ids[i])\n",
    "#         top_system_id.append(mapping)\n",
    "#         dic_recommendation = {question_id: top_system for question_id, top_system in zip(unanswered_embedding_index,top_system_id)}\n",
    "    \n",
    "#     return dic_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative method to avoid memory overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 46/46 [07:45<00:00, 10.12s/it]\n"
     ]
    }
   ],
   "source": [
    "import gc  # Garbage collector\n",
    "\n",
    "def get_recommendation_top_batched(top_n, batch_size=1000):\n",
    "    num_test = unanswered_embeddings.shape[0]\n",
    "\n",
    "    for start in tqdm(range(0, num_test, batch_size), desc=\"Processing Batches\"):\n",
    "        end = min(start + batch_size, num_test)\n",
    "        batch = unanswered_embeddings[start:end]\n",
    "\n",
    "        # Compute similarities (rows = questions, columns = users)\n",
    "        batch_similarities = np.dot(batch, user_embeddings.T) \n",
    "\n",
    "        # Get top-N indices \n",
    "        top_indices = np.argsort(-batch_similarities, axis=1)[:, :top_n] \n",
    "        \n",
    "        del batch_similarities  \n",
    "        gc.collect()  # Force Python to release memory\n",
    "\n",
    "        # Yield results one batch at a time\n",
    "        for i, question_id in enumerate(unanswered_embedding_index[start:end]):\n",
    "            yield question_id, [user_ids[j] for j in top_indices[i]]\n",
    "\n",
    "# Use the generator directly instead of storing everything\n",
    "dic_recommendation = {qid: recommendations for qid, recommendations in get_recommendation_top_batched(top_n=50)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping our **ground truth** that is the users that answered the question in real life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert QuestionTags from lists to tuples\n",
    "df_merged_test[\"QuestionTags\"] = df_merged_test[\"QuestionTags\"].apply(tuple)\n",
    "\n",
    "# Group AnswerOwnerId by QuestionId and QuestionTags\n",
    "grouped_df = (\n",
    "    df_merged_test.groupby([\"QuestionId\", \"QuestionTags\", \"QuestionTitle\"])[\"AnswerOwnerId\"]\n",
    "    .apply(list)  # Combine AnswerOwnerId values into a list\n",
    "    .reset_index()\n",
    "    .rename(columns={\"AnswerOwnerId\": \"GroundTruth\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_dic = grouped_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Ground Truth with Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_accuracy(ground_truth_dic, top_users_list, top_n):\n",
    "    tp = 0\n",
    "    \n",
    "    for question in ground_truth_dic:    \n",
    "        # Checking if it is in the answer\n",
    "        users_recommendation = top_users_list[question[\"QuestionId\"]][:top_n]\n",
    "        users_ground_truth = question[\"GroundTruth\"]\n",
    "        if set(users_recommendation) & set(users_ground_truth):\n",
    "            tp += 1\n",
    "            \n",
    "    print(tp)\n",
    "    return tp/len(ground_truth_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1694\n",
      "2420\n",
      "3809\n"
     ]
    }
   ],
   "source": [
    "top_users = [10, 20, 50]\n",
    "results = []\n",
    "\n",
    "for top_n in top_users:\n",
    "    results.append({\n",
    "        \"acc\": top_n_accuracy(ground_truth_dic, dic_recommendation, top_n),\n",
    "        \"top\": top_n,\n",
    "        \"type\": \"nlp_sentence_transformer_tag\"\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'acc': 0.059713067080263665, 'top': 10, 'type': 'nlp_sentence_transformer'},\n",
       " {'acc': 0.08530438154323382, 'top': 20, 'type': 'nlp_sentence_transformer'},\n",
       " {'acc': 0.13426627656949486, 'top': 50, 'type': 'nlp_sentence_transformer'}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"prototype_embedding_tags.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
